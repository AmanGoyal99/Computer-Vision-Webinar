{"cells":[{"metadata":{},"cell_type":"markdown","source":"# DOWNLOADING THE DATASET"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from keras.datasets import imdb\n","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocabulary_size = 5000\n(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)\nprint('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))","execution_count":2,"outputs":[{"output_type":"stream","text":"Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n17465344/17464789 [==============================] - 0s 0us/step\nLoaded dataset with 25000 training samples, 25000 test samples\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# DATA EXPLORATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('---review---')\nprint(X_train[6])\nprint('---label---')\nprint(y_train[6])","execution_count":3,"outputs":[{"output_type":"stream","text":"---review---\n[1, 2, 365, 1234, 5, 1156, 354, 11, 14, 2, 2, 7, 1016, 2, 2, 356, 44, 4, 1349, 500, 746, 5, 200, 4, 4132, 11, 2, 2, 1117, 1831, 2, 5, 4831, 26, 6, 2, 4183, 17, 369, 37, 215, 1345, 143, 2, 5, 1838, 8, 1974, 15, 36, 119, 257, 85, 52, 486, 9, 6, 2, 2, 63, 271, 6, 196, 96, 949, 4121, 4, 2, 7, 4, 2212, 2436, 819, 63, 47, 77, 2, 180, 6, 227, 11, 94, 2494, 2, 13, 423, 4, 168, 7, 4, 22, 5, 89, 665, 71, 270, 56, 5, 13, 197, 12, 161, 2, 99, 76, 23, 2, 7, 419, 665, 40, 91, 85, 108, 7, 4, 2084, 5, 4773, 81, 55, 52, 1901]\n---label---\n1\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"word2id = imdb.get_word_index()\nid2word = {i: word for word, i in word2id.items()}\nprint('---review with words---')\nprint([id2word.get(i, ' ') for i in X_train[6]])\nprint('---label---')\nprint(y_train[6])","execution_count":4,"outputs":[{"output_type":"stream","text":"Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n1646592/1641221 [==============================] - 0s 0us/step\n---review with words---\n['the', 'and', 'full', 'involving', 'to', 'impressive', 'boring', 'this', 'as', 'and', 'and', 'br', 'villain', 'and', 'and', 'need', 'has', 'of', 'costumes', 'b', 'message', 'to', 'may', 'of', 'props', 'this', 'and', 'and', 'concept', 'issue', 'and', 'to', \"god's\", 'he', 'is', 'and', 'unfolds', 'movie', 'women', 'like', \"isn't\", 'surely', \"i'm\", 'and', 'to', 'toward', 'in', \"here's\", 'for', 'from', 'did', 'having', 'because', 'very', 'quality', 'it', 'is', 'and', 'and', 'really', 'book', 'is', 'both', 'too', 'worked', 'carl', 'of', 'and', 'br', 'of', 'reviewer', 'closer', 'figure', 'really', 'there', 'will', 'and', 'things', 'is', 'far', 'this', 'make', 'mistakes', 'and', 'was', \"couldn't\", 'of', 'few', 'br', 'of', 'you', 'to', \"don't\", 'female', 'than', 'place', 'she', 'to', 'was', 'between', 'that', 'nothing', 'and', 'movies', 'get', 'are', 'and', 'br', 'yes', 'female', 'just', 'its', 'because', 'many', 'br', 'of', 'overly', 'to', 'descent', 'people', 'time', 'very', 'bland']\n---label---\n1\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Maximum review length: {}'.format(\nlen(max((X_train + X_test), key=len))))","execution_count":5,"outputs":[{"output_type":"stream","text":"Maximum review length: 2697\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Minimum review length: {}'.format(\nlen(min((X_test + X_test), key=len))))","execution_count":6,"outputs":[{"output_type":"stream","text":"Minimum review length: 14\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# DATA PREPROCESSING"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import sequence\nmax_words = 500\nX_train = sequence.pad_sequences(X_train, maxlen=max_words)\nX_test = sequence.pad_sequences(X_test, maxlen=max_words)","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# BUILDING MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import Sequential\nfrom keras.layers import Embedding, LSTM, Dense, Dropout\nembedding_size=32\nmodel=Sequential()\nmodel.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\nmodel.add(LSTM(100))\nmodel.add(Dense(1, activation='sigmoid'))\nprint(model.summary())","execution_count":8,"outputs":[{"output_type":"stream","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 500, 32)           160000    \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 100)               53200     \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 101       \n=================================================================\nTotal params: 213,301\nTrainable params: 213,301\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# TRAINING THE MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='binary_crossentropy', \n             optimizer='adam', \n             metrics=['accuracy'])","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\nnum_epochs = 3\nX_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\nX_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\nmodel.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs)","execution_count":10,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n","name":"stderr"},{"output_type":"stream","text":"Train on 24936 samples, validate on 64 samples\nEpoch 1/3\n24936/24936 [==============================] - 199s 8ms/step - loss: 0.4701 - accuracy: 0.7692 - val_loss: 0.2353 - val_accuracy: 0.9219\nEpoch 2/3\n24936/24936 [==============================] - 196s 8ms/step - loss: 0.2891 - accuracy: 0.8839 - val_loss: 0.2470 - val_accuracy: 0.9062\nEpoch 3/3\n24936/24936 [==============================] - 199s 8ms/step - loss: 0.2409 - accuracy: 0.9063 - val_loss: 0.2242 - val_accuracy: 0.9375\n","name":"stdout"},{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7fee59e0c630>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate(X_test, y_test, verbose=0)\nprint('Test accuracy:', scores[1])","execution_count":11,"outputs":[{"output_type":"stream","text":"Test accuracy: 0.8638399839401245\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict=model.predict_classes(X_test)\npredict_classes=predict.reshape(len(X_test))","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_original_text(i):\n    word_to_id = imdb.get_word_index()\n    word_to_id = {k:(v+3) for k,v in word_to_id.items()}\n    word_to_id[\"<PAD>\"] = 0\n    word_to_id[\"<START>\"] = 1\n    word_to_id[\"<UNK>\"] = 2\n\n    id_to_word = {value:key for key,value in word_to_id.items()}\n    return ' '.join(id_to_word[id] for id in X_test[i])","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SentimentDict={1:'positive', 0:'negative'}\ndef display_test_sentiment(i):\n    print(get_original_text(i))\n    print('label: ', SentimentDict[y_test[i]], ', prediction: ', SentimentDict[predict_classes[i]])","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_test_sentiment(4)","execution_count":23,"outputs":[{"output_type":"stream","text":"<PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <START> like some other people wrote i'm a die hard mario fan and i loved this game br br this game starts slightly boring but trust me it's worth it as soon as you start your hooked the levels are fun and <UNK> they will hook you <UNK> your mind turns to <UNK> i'm not kidding this game is also <UNK> and is beautifully done br br to keep this spoiler free i have to keep my mouth shut about details but please try this game it'll be worth it br br story 9 9 action 10 1 it's that good <UNK> 10 attention <UNK> 10 average 10\nlabel:  positive , prediction:  positive\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}